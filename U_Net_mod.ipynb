{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U Net_mod.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjayKumarGogineni777/Heart-Sound-Segmentation/blob/master/U_Net_mod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1eqm2nhuZtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOO7cOg0ujip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "#mat_contents = sio.loadmat('/content/gdrive/My Drive/1D U Net/features_normal.mat')\n",
        "#labels = sio.loadmat('/content/gdrive/My Drive/1D U Net/states_normal.mat')\n",
        "\n",
        "mat_contents = sio.loadmat('/content/gdrive/My Drive/1D U Net/LSTM_classification/LS1_features_all_no_EWT')\n",
        "labels = sio.loadmat('/content/gdrive/My Drive/1D U Net/states_normal.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9EAW9631aup",
        "colab_type": "code",
        "outputId": "d09dc7a0-d0b2-479e-9c33-9fb57e704944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k = 770\n",
        "t1 = mat_contents['LS1_features'][0][k]\n",
        "t1_shape = mat_contents['LS1_features'][0][k].shape\n",
        "t1_shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zch9lTeU329D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnt3 = 0\n",
        "for i in range(792):\n",
        "  a = labels['LS1_states'][0][i].shape\n",
        "  cnt3 = cnt3+a[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmotWRzz136l",
        "colab_type": "code",
        "outputId": "cc9f5de5-25bf-43e8-8b40-2820dcb1c55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnt3/8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62340.625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwtwitUc2Rbq",
        "colab_type": "code",
        "outputId": "5bedcb8c-0000-4289-ce0a-9df962ba43af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1475//64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0K8e6Ewp0b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "elements = 56339\n",
        "temp2 = torch.randn(elements,64)\n",
        "cnt2 = 0\n",
        "for i in range(792):\n",
        "  a = labels['concat_states'][0][i].shape\n",
        "  num = a[0]//8\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    if j*8+64< a[0]:\n",
        "      a2 = labels['concat_states'][0][i][j*8:(j*8+64)]\n",
        "    \n",
        "      a2 = torch.from_numpy(np.transpose(a2))\n",
        "      temp2[cnt2] = a2\n",
        "      cnt2 = cnt2+1\n",
        "      \n",
        "temp = torch.randn(elements, 4, 64)\n",
        "cnt2 = 0\n",
        "for i in range(792):\n",
        "  a = mat_contents['LS1_features'][0][i].shape\n",
        "  num = a[0]//8   \n",
        "  \n",
        "  for j in range(num):\n",
        "    if j*8+64< a[0]:\n",
        "      a2 = mat_contents['LS1_features'][0][i][j*8:(j*8+64)]\n",
        "    \n",
        "      a2 = torch.from_numpy(np.transpose(a2))\n",
        "      temp[cnt2] = a2\n",
        "      cnt2 = cnt2+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsi7YAbRw4cO",
        "colab_type": "code",
        "outputId": "427a3853-78ea-411b-905d-85471640511d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "temp2[50000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3.,\n",
              "        4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3.,\n",
              "        4., 4., 4., 4., 4., 4., 4., 4., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJub9h0hABoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a77a156b-be8d-4645-863c-9252b915c991",
        "id": "WpoOVamgAB3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#### Main code\n",
        "## Using blocks\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU ) * 1'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, 5,1, 2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, 5, 1, 2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "      \n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x   \n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool1d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x      \n",
        "\n",
        "      \n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose1d(in_ch, in_ch//2,4,2,1)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        ### x2 is from downsampling path\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        #diffY = x2.size()[2] - x1.size()[2]\n",
        "        #diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        #x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "        #                diffY // 2, diffY - diffY//2))\n",
        "        \n",
        "        # for padding issues, see \n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x   \n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch,5, 1, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x      \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        #n_channels = 4, n_classes = 4\n",
        "        self.inc = inconv(4, 8)\n",
        "        self.down1 = down(8, 16)\n",
        "        self.down2 = down(16, 32)\n",
        "        self.down3 = down(32, 64)\n",
        "        self.down4 = down(64, 128)\n",
        "        \n",
        "        self.up1 = up(128, 64)\n",
        "        self.up2 = up(64, 32)\n",
        "        self.up3 = up(32, 16)\n",
        "        self.up4 = up(16, 8)\n",
        "        \n",
        "        \n",
        "        self.outc = outconv(8, 4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      \n",
        "        x1 = self.inc(x)     \n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        #return F.sigmoid(x)\n",
        "        return x\n",
        "model = UNet()\n",
        "sample = temp[64:128]\n",
        "target = temp2[0]\n",
        "out = model(sample)\n",
        "out.size()      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ADAM optimiser\n",
        "\n",
        "### training loop\n",
        "\n",
        "\n",
        "def softmax_mod(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "def nll_indexing(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1].mean()\n",
        "\n",
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True)\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))\n",
        "\n",
        "\n",
        "#soft = softmax_mod(out).transpose(1,2)\n",
        "#soft.shape\n",
        "lr = 1e-4\n",
        "epochs = 4\n",
        "#n = 7391\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "loss_func2 = torch.nn.L1Loss\n",
        "#def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
        "\n",
        "def accuracy_mod(out, yb): return (torch.argmax(out, dim=2)==yb-1).float().mean()\n",
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/EWT/models/EWT_LS1_155_epochs'))\n",
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/EWT/stride_8/models/speech_8_strides_44_epochs_stride_64'))\n",
        "for epoch in range(epochs):\n",
        "    for i in range(100): ### i = 1:100 for training\n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = temp[start_i:end_i]\n",
        "        #yb = y_f[start_i:end_i]\n",
        "        target = temp2[start_i:end_i]\n",
        "            \n",
        "        out = model(xb)\n",
        "        #loss = loss_func(model(xb), yb.long())\n",
        "        #loss = nll2((log_softmax(model(xb))),y_onehot.long())\n",
        "        loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "        #rint(loss)\n",
        "        #loss = cross_entropy(out.squeeze(),yb)\n",
        "        #loss = criterion(out.transpose(1, 2), torch.max(yb.transpose(1, 2), 1)[1])\n",
        "        \n",
        "        \n",
        "        accuracy = accuracy_mod(softmax_mod(out.transpose(1, 2)),target.long())\n",
        "\n",
        "        loss.backward()\n",
        "      #for param in model.parameters():\n",
        "        #print(param.grad.data.sum())\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    print('accuracy',accuracy)\n",
        "    print(' > Epoch {:2d} loss: {:.3f}'.format((epoch+1), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy tensor(0.9336)\n",
            " > Epoch  1 loss: 0.178\n",
            "accuracy tensor(0.9348)\n",
            " > Epoch  2 loss: 0.178\n",
            "accuracy tensor(0.9343)\n",
            " > Epoch  3 loss: 0.168\n",
            "accuracy tensor(0.9382)\n",
            " > Epoch  4 loss: 0.156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIG5SuTXDThs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = model.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/EWT/stride_8/models'\n",
        "torch.save(st, mdl_path+'/speech_8_strides_48_epochs_stride_64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoZ-1JbiDO1d",
        "colab_type": "code",
        "outputId": "5c2b0bcd-0ae1-4347-945a-4b2853d296a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnt_acc = 0\n",
        "acc_total = 0\n",
        "#for i in range(650,795,1):\n",
        "for i in range(90, 105, 1):\n",
        "  start_i = i*bs\n",
        "  end_i = start_i+bs\n",
        "  xb = temp[start_i:end_i]\n",
        "  #yb = y_f[start_i:end_i]\n",
        "  target = temp2[start_i:end_i]\n",
        "            \n",
        "  out = model(xb)\n",
        "  #loss = loss_func(model(xb), yb.long())\n",
        "        #loss = nll2((log_softmax(model(xb))),y_onehot.long())\n",
        "  loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "  #loss = cross_entropy(out.squeeze(),yb)\n",
        "  #loss = criterion(out.transpose(1, 2), torch.max(yb.transpose(1, 2), 1)[1])\n",
        "  accuracy = accuracy_mod(softmax_mod(out.transpose(1, 2)),target.long())\n",
        "  \n",
        "  \n",
        "  acc_total = acc_total + accuracy\n",
        "  cnt_acc = cnt_acc+1\n",
        "  #print('loss',loss)\n",
        "  #print('acc',accuracy)\n",
        "print(acc_total/cnt_acc)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9058)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dNMw1m6oNBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_preds = []\n",
        "bs = 64\n",
        "#for i in range(750, 790):\n",
        "for i in range(80, 105, 1):\n",
        "    \n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i]\n",
        "    \n",
        "    target = temp2[start_i:end_i]\n",
        "        \n",
        "    out = model(xb)\n",
        "    sm_preds_val = softmax_mod(out.transpose(1, 2))\n",
        "    sm_preds_fn = torch.argmax(sm_preds_val, dim=2)+1\n",
        "    sm_preds.append(sm_preds_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQtmQh2i4YJa",
        "colab": {}
      },
      "source": [
        "\n",
        "target_comp = []\n",
        "#for i in range(750, 790):\n",
        "for i in range(80, 105, 1):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i]\n",
        "    #yb = y_f[start_i:end_i]\n",
        "    target = temp2[start_i:end_i]\n",
        "    target_comp.append(target)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STtlHD-Z6jYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = []\n",
        "pred = []\n",
        "for i in range(25):\n",
        "  s1_true = np.where(target_comp[i][0] == 1)\n",
        "  s1_pred = np.where(sm_preds[i][0] == 1)\n",
        "  tr.append(s1_true)\n",
        "  pred.append(s1_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RQwAwomn4YJe",
        "outputId": "7872582d-f45f-4bd9-c3ec-0dac466e02cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(25):\n",
        "    print(i)\n",
        "    print(tr[i])\n",
        "    print(pred[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(array([ 1,  2,  3,  4,  5,  6,  7, 44, 45, 46, 47, 48, 49, 50]),)\n",
            "(array([ 1,  2,  3,  4,  5,  6,  7,  8, 44, 45, 46, 47, 48, 49]),)\n",
            "1\n",
            "(array([32, 33, 34, 35, 36, 37, 38]),)\n",
            "(array([32, 33, 34, 35, 36, 37, 38]),)\n",
            "2\n",
            "(array([10, 11, 12, 13, 14, 15, 16, 49, 50, 51, 52, 53, 54, 55]),)\n",
            "(array([ 8,  9, 10, 11, 12, 13, 14, 49, 50, 51, 52, 53, 54, 55]),)\n",
            "3\n",
            "(array([ 4,  5,  6,  7,  8,  9, 10, 50, 51, 52, 53, 54, 55, 56]),)\n",
            "(array([ 5,  6,  7,  8,  9, 10, 11, 50, 51, 52, 53, 54, 55, 56]),)\n",
            "4\n",
            "(array([49, 50, 51, 52, 53, 54, 55]),)\n",
            "(array([49, 50, 51, 52, 53, 54, 55]),)\n",
            "5\n",
            "(array([24, 25, 26, 27, 28, 29, 30]),)\n",
            "(array([23, 24, 25, 26, 27, 28, 29]),)\n",
            "6\n",
            "(array([ 0, 41, 42, 43, 44, 45, 46, 47]),)\n",
            "(array([ 0,  1,  2,  3, 40, 41, 42, 43, 44, 45, 46]),)\n",
            "7\n",
            "(array([ 0, 36, 37, 38, 39, 40, 41, 42]),)\n",
            "(array([ 0,  1,  2, 39, 40, 41, 42, 43, 44, 45]),)\n",
            "8\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 45, 46, 47, 48, 49, 50, 51]),)\n",
            "(array([ 7,  8,  9, 10, 11, 12, 13, 46, 47, 48, 49, 50, 51]),)\n",
            "9\n",
            "(array([ 5,  6,  7,  8,  9, 10, 11, 41, 42, 43, 44, 45, 46, 47]),)\n",
            "(array([ 5,  6,  7,  8,  9, 10, 11, 41, 42, 43, 44, 45, 46]),)\n",
            "10\n",
            "(array([15, 16, 17, 18, 19, 20, 21]),)\n",
            "(array([14, 15, 16, 17, 18, 19, 20]),)\n",
            "11\n",
            "(array([26, 27, 28, 29, 30, 31, 32, 61, 62, 63]),)\n",
            "(array([25, 26, 27, 28, 29, 30, 31, 60, 61, 62, 63]),)\n",
            "12\n",
            "(array([ 0,  1,  2,  3, 30, 31, 32, 33, 34, 35, 36, 62, 63]),)\n",
            "(array([ 0,  1,  2,  3, 29, 30, 31, 32, 33, 34, 35, 61, 62, 63]),)\n",
            "13\n",
            "(array([24, 25, 26, 27, 28, 29, 30]),)\n",
            "(array([25, 26, 27, 28, 29, 30, 31]),)\n",
            "14\n",
            "(array([ 0,  1,  2,  3,  4, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([0, 1, 2, 3, 4]),)\n",
            "15\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 54, 55, 56, 57, 58, 59, 60]),)\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 54, 55, 56, 57, 58, 59, 60]),)\n",
            "16\n",
            "(array([ 3,  4,  5,  6,  7,  8,  9, 36, 37, 38, 39, 40, 41, 42]),)\n",
            "(array([ 3,  4,  5,  6,  7,  8, 35, 36, 37, 38, 39, 40, 41]),)\n",
            "17\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([ 0,  1,  2,  3,  4,  5, 56, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "18\n",
            "(array([ 1,  2,  3,  4,  5,  6,  7, 62, 63]),)\n",
            "(array([ 3,  4,  5,  6,  7,  8,  9, 60, 61, 62, 63]),)\n",
            "19\n",
            "(array([29, 30, 31, 32, 33, 34, 35]),)\n",
            "(array([29, 30, 31, 32, 33, 34, 35, 36]),)\n",
            "20\n",
            "(array([ 0,  1,  2,  3, 32, 33, 34, 35, 36, 37, 38]),)\n",
            "(array([ 0,  1,  2,  3,  4,  5, 33, 34, 35, 36, 37, 38, 39]),)\n",
            "21\n",
            "(array([10, 11, 12, 13, 14, 15, 16, 60, 61, 62, 63]),)\n",
            "(array([11, 12, 13, 14, 15, 16, 17, 60, 61, 62, 63]),)\n",
            "22\n",
            "(array([32, 33, 34, 35, 36, 37, 38]),)\n",
            "(array([32, 33, 34, 35, 36, 37, 38, 39]),)\n",
            "23\n",
            "(array([18, 19, 20, 21, 22, 23, 24, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([18, 19, 20, 21, 22, 23, 24, 58, 59, 60, 61, 62, 63]),)\n",
            "24\n",
            "(array([15, 16, 17, 18, 19, 20, 21, 54, 55, 56, 57, 58, 59, 60]),)\n",
            "(array([15, 16, 17, 18, 19, 20, 21, 55, 56, 57, 58, 59, 60, 61, 62]),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QcMTF6DKI3g",
        "colab_type": "code",
        "outputId": "aa90fc7a-9062-4227-d8e6-51681cd81fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tr = []\n",
        "pred = []\n",
        "for i in range(25):\n",
        "  s1_true = np.where(target_comp[i][0] == 3)\n",
        "  s1_pred = np.where(sm_preds[i][0] == 3)\n",
        "  tr.append(s1_true)\n",
        "  pred.append(s1_pred)\n",
        "for i in range(25):\n",
        "    print(i)\n",
        "    print(tr[i])\n",
        "    print(pred[i])  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(array([20, 21, 22, 23, 24, 62, 63]),)\n",
            "(array([20, 21, 22, 23, 62, 63]),)\n",
            "1\n",
            "(array([ 9, 10, 11, 12, 13, 47, 48, 49, 50, 51]),)\n",
            "(array([ 9, 10, 11, 12, 13, 47, 48, 49, 50, 51]),)\n",
            "2\n",
            "(array([28, 29, 30, 31, 32, 62, 63]),)\n",
            "(array([30, 31, 32, 33, 62, 63]),)\n",
            "3\n",
            "(array([24, 25, 26, 27, 28]),)\n",
            "(array([23, 24, 25, 26, 27]),)\n",
            "4\n",
            "(array([ 8,  9, 10, 11, 12]),)\n",
            "(array([ 8,  9, 10, 11, 12]),)\n",
            "5\n",
            "(array([39, 40, 41, 42, 43]),)\n",
            "(array([40, 41, 42, 43]),)\n",
            "6\n",
            "(array([14, 15, 16, 17, 18, 60, 61, 62, 63]),)\n",
            "(array([14, 15, 16, 17, 18, 59, 60, 61, 62]),)\n",
            "7\n",
            "(array([13, 14, 15, 16, 17, 54, 55, 56, 57, 58]),)\n",
            "(array([13, 14, 15, 16, 17, 55, 56, 57, 58, 59]),)\n",
            "8\n",
            "(array([23, 24, 25, 26, 27, 62, 63]),)\n",
            "(array([23, 24, 25, 26, 27]),)\n",
            "9\n",
            "(array([20, 21, 22, 23, 24, 57, 58, 59, 60, 61]),)\n",
            "(array([20, 21, 22, 23, 24, 57, 58, 59, 60]),)\n",
            "10\n",
            "(array([33, 34, 35, 36, 37]),)\n",
            "(array([34, 35, 36, 37, 38]),)\n",
            "11\n",
            "(array([ 7,  8,  9, 10, 11, 41, 42, 43, 44, 45]),)\n",
            "(array([ 7,  8,  9, 10, 11, 40, 41, 42, 43, 44]),)\n",
            "12\n",
            "(array([10, 11, 12, 13, 14, 43, 44, 45, 46, 47]),)\n",
            "(array([10, 11, 12, 13, 14, 43, 44, 45, 46, 47, 48]),)\n",
            "13\n",
            "(array([ 2,  3,  4,  5,  6, 42, 43, 44, 45, 46]),)\n",
            "(array([ 2,  3,  4,  5, 42, 43, 44, 45, 46]),)\n",
            "14\n",
            "(array([17, 18, 19, 20, 21]),)\n",
            "(array([17, 18, 19, 20, 21]),)\n",
            "15\n",
            "(array([23, 24, 25, 26, 27]),)\n",
            "(array([23, 24, 25, 26, 27]),)\n",
            "16\n",
            "(array([18, 19, 20, 21, 22, 51, 52, 53, 54, 55]),)\n",
            "(array([18, 19, 20, 21, 22, 51, 52, 53, 54]),)\n",
            "17\n",
            "(array([10, 11, 12, 13, 14]),)\n",
            "(array([12, 13, 14, 15]),)\n",
            "18\n",
            "(array([20, 21, 22, 23, 24]),)\n",
            "(array([21, 22, 23, 24, 25]),)\n",
            "19\n",
            "(array([ 5,  6,  7,  8,  9, 45, 46, 47, 48, 49]),)\n",
            "(array([ 5,  6,  7,  8,  9, 47, 48, 49, 50]),)\n",
            "20\n",
            "(array([14, 15, 16, 17, 18, 48, 49, 50, 51, 52]),)\n",
            "(array([14, 15, 16, 17, 51, 52, 53, 54, 55, 56]),)\n",
            "21\n",
            "(array([29, 30, 31, 32, 33]),)\n",
            "(array([29, 30, 31, 32, 33]),)\n",
            "22\n",
            "(array([ 4,  5,  6,  7,  8, 49, 50, 51, 52, 53]),)\n",
            "(array([ 4,  5,  6,  7,  8, 49, 50, 51, 52, 53]),)\n",
            "23\n",
            "(array([34, 35, 36, 37, 38]),)\n",
            "(array([33, 34, 35, 36, 37]),)\n",
            "24\n",
            "(array([29, 30, 31, 32, 33]),)\n",
            "(array([30, 31, 32, 33, 34]),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBBfEEQd4Xwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzQC69gg4Xs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVt35LxB4Xqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTD0f1O44Xn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQoov474Xk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYhSQWgE4XfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqDq2j94ok7I",
        "colab_type": "code",
        "outputId": "7db97084-5372-44be-dd4c-af0a477e2075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "target[18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "        4., 4., 4., 4., 4., 4., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2.,\n",
              "        2., 3., 3., 3., 3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "        4., 4., 4., 4., 4., 4., 4., 4., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9otfcJUkoSJR",
        "colab_type": "code",
        "outputId": "03e0c9f3-0533-4ee1-bedc-67df08f19802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "sm_preds[0][18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBxl_YqK3CtQ",
        "colab_type": "code",
        "outputId": "c0a876a4-b38d-4afc-891b-84994450fdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "k = 18\n",
        "sm_final = sm_preds[0][k]\n",
        "for j in range(1,63):\n",
        "  #print(j) 1 to 62\n",
        "  if sm_preds[0][k][j] == (sm_final[j-1]+1)//4:\n",
        "    sm_final[j] = sm_preds[0][k][j]\n",
        "  else:\n",
        "    sm_final[j] = sm_final[j-1]\n",
        "\n",
        "    \n",
        "sm_final  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlBwn9DH4APm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl6QJmx656Kr",
        "colab_type": "code",
        "outputId": "76e09f00-6ef8-43d4-a888-26df428d32c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "56339//64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hrnj4oT5wOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 880\n",
        "bs = 64\n",
        "start_i = i*bs\n",
        "end_i = start_i+bs\n",
        "xb = temp[start_i:end_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlSQoad66jTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emLDRfgc4pTW",
        "colab_type": "code",
        "outputId": "bc0aa768-557f-49a7-9b2a-5f8405c88d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2qKqBkOK2V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "temp2 = torch.randn(elements, 64)\n",
        "cnt2 = 0\n",
        "for i in range(760):\n",
        "  a = labels['LS1_states'][0][i].shape\n",
        "  num = a[0]//64\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    a2 = labels['LS1_states'][0][i][j*64:(j*64+64)]\n",
        "    a2 = torch.from_numpy(np.asarray(a2))\n",
        "    temp2[cnt2] = a2[0]\n",
        "    cnt2 = cnt2+1\n",
        "    #a2 = torch.from_numpy(np.transpose(a2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ0Tly-zLGYi",
        "colab_type": "code",
        "outputId": "dd5c3eea-9469-4810-8f9a-dab013f44345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "temp2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7104, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQypKT5Rz6P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Satets/ Labels\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "temp2 = torch.randn(elements,64)\n",
        "cnt2 = 0\n",
        "for i in range(760):\n",
        "  a = labels['LS1_states'][0][i].shape\n",
        "  num = a[0]//64\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    a2 = labels['LS1_states'][0][i][j*64:(j*64+64)]\n",
        "    \n",
        "    a2 = torch.from_numpy(np.transpose(a2))\n",
        "    temp2[cnt2] = a2\n",
        "    cnt2 = cnt2+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiMp7P0Cdhcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_f = torch.zeros(elements,4,64)\n",
        "for i in range(elements):\n",
        "  for j in range(4):\n",
        "      for k in range(64):\n",
        "        if temp2[i][k] == 1:\n",
        "          y_f[i][0][k] = 1\n",
        "        elif temp2[i][k] == 2:\n",
        "          y_f[i][1][k] = 1\n",
        "        elif temp2[i][k] == 3:\n",
        "          y_f[i][2][k] = 1\n",
        "        elif temp2[i][k] == 4:\n",
        "          y_f[i][3][k] = 1\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIVVcH-Ugu4-",
        "colab_type": "code",
        "outputId": "a8a3495c-d0df-4539-e121-edafa399b6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "y_f[0][0][0:63]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ6ImxJjqYwP",
        "colab_type": "code",
        "outputId": "01ba54a1-3717-4a29-fb47-6c45e017edb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "115*64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7360"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrNxO4OKvSG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Features\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "temp = torch.randn(elements,4,64)\n",
        "cnt = 0\n",
        "for i in range(760):\n",
        "  a = mat_contents['LS1_features'][0][i].shape\n",
        "  num = a[0]//64\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    a2 = mat_contents['LS1_features'][0][i][j*64:(j*64+64)]\n",
        "    a2 = torch.from_numpy(np.transpose(a2))\n",
        "    #a2 = torch.from_numpy(np.array(a2))\n",
        "    temp[cnt] = a2\n",
        "    cnt = cnt+1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAh9YOSTbseG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FxbtFih0b1Bb",
        "colab": {}
      },
      "source": [
        "## Using blocks\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU ) * 1'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, out_ch, 5,1, 2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_ch, out_ch, 5, 1, 2),\n",
        "            nn.BatchNorm1d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "      \n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x   \n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool1d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x      \n",
        "\n",
        "      \n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose1d(in_ch, in_ch//2,4,2,1)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        ### x2 is from downsampling path\n",
        "        x1 = self.up(x1)\n",
        "        \n",
        "        # input is CHW\n",
        "        #diffY = x2.size()[2] - x1.size()[2]\n",
        "        #diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        #x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "        #                diffY // 2, diffY - diffY//2))\n",
        "        \n",
        "        # for padding issues, see \n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x   \n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch,5, 1, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bXbwiJrXb1Bi",
        "colab": {}
      },
      "source": [
        "#### Main code\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        #n_channels = 4, n_classes = 4\n",
        "        self.inc = inconv(4, 8)\n",
        "        self.down1 = down(8, 16)\n",
        "        self.down2 = down(16, 32)\n",
        "        self.down3 = down(32, 64)\n",
        "        self.down4 = down(64, 128)\n",
        "        \n",
        "        self.up1 = up(128, 64)\n",
        "        self.up2 = up(64, 32)\n",
        "        self.up3 = up(32, 16)\n",
        "        self.up4 = up(16, 8)\n",
        "        \n",
        "        \n",
        "        self.outc = outconv(8, 4)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      \n",
        "        x1 = self.inc(x)     \n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        #return F.sigmoid(x)\n",
        "        return x\n",
        "model = UNet()\n",
        "sample = temp[64:128]\n",
        "target = temp2[0]\n",
        "out = model(sample)\n",
        "out.size()      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "47ae5a75-6282-4848-a1e6-986c4254bb72",
        "id": "Xbh3gez8b1Bk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = UNet()\n",
        "sample = temp[64:128]\n",
        "target = temp2[0]\n",
        "out = model(sample)\n",
        "out.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvXlI86b7vie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4LpuAsf71lN",
        "colab_type": "code",
        "outputId": "cc8665c1-1151-4625-98a7-692e56919e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "### training loop\n",
        "\n",
        "\n",
        "def softmax_mod(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "def nll_indexing(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1].mean()\n",
        "\n",
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True)\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))\n",
        "\n",
        "\n",
        "#soft = softmax_mod(out).transpose(1,2)\n",
        "#soft.shape\n",
        "lr = 5e-4\n",
        "epochs = 10\n",
        "n = 7391\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "loss_func2 = torch.nn.L1Loss\n",
        "#def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
        "\n",
        "def accuracy_mod(out, yb): return (torch.argmax(out, dim=2)==yb-1).float().mean()\n",
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(100): ### i = 1:100 for training\n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = temp[start_i:end_i]\n",
        "        yb = y_f[start_i:end_i]\n",
        "        target = temp2[start_i:end_i]\n",
        "            \n",
        "        out = model(xb)\n",
        "        #loss = loss_func(model(xb), yb.long())\n",
        "        #loss = nll2((log_softmax(model(xb))),y_onehot.long())\n",
        "        loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "        #rint(loss)\n",
        "        #loss = cross_entropy(out.squeeze(),yb)\n",
        "        #loss = criterion(out.transpose(1, 2), torch.max(yb.transpose(1, 2), 1)[1])\n",
        "        \n",
        "        \n",
        "        accuracy = accuracy_mod(softmax_mod(out.transpose(1, 2)),target.long())\n",
        "        #print('accuracy',accuracy)\n",
        "        \n",
        "        #print('accuracy:',accuracy1(model(xb), yb.long()))\n",
        "        loss.backward()\n",
        "        #print(out[0])\n",
        "        #print(yb[0])\n",
        "        with torch.no_grad():\n",
        "            for p in model.parameters(): p -= p.grad * lr\n",
        "            model.zero_grad()\n",
        "    print(' > Epoch {:2d} loss: {:.3f}'.format((epoch+1), loss.item()))\n",
        "    print('accuracy',accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Epoch  1 loss: 1.302\n",
            "accuracy tensor(0.5154)\n",
            " > Epoch  2 loss: 1.293\n",
            "accuracy tensor(0.5193)\n",
            " > Epoch  3 loss: 1.283\n",
            "accuracy tensor(0.5190)\n",
            " > Epoch  4 loss: 1.273\n",
            "accuracy tensor(0.5208)\n",
            " > Epoch  5 loss: 1.263\n",
            "accuracy tensor(0.5193)\n",
            " > Epoch  6 loss: 1.253\n",
            "accuracy tensor(0.5178)\n",
            " > Epoch  7 loss: 1.243\n",
            "accuracy tensor(0.5195)\n",
            " > Epoch  8 loss: 1.233\n",
            "accuracy tensor(0.5190)\n",
            " > Epoch  9 loss: 1.222\n",
            "accuracy tensor(0.5203)\n",
            " > Epoch 10 loss: 1.212\n",
            "accuracy tensor(0.5210)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAyIp_ds8caI",
        "colab_type": "code",
        "outputId": "122188ef-b76f-47fb-e146-2cdec14c1c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/1D U Net/models/16_epochs'\n",
        "torch.save(model, PATH)\n",
        "torch.max(softmax_mod(model(temp[0:64])[0]).transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type UNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type inconv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type double_conv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type down. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type up. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type outconv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 3, 3, 1, 1,\n",
              "        3, 1, 1, 3, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4,\n",
              "        4, 4, 2, 3, 1, 1, 3, 1, 1, 1, 3, 3, 2, 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lGRpPMFCcKK7",
        "outputId": "7366adfa-af94-4e0a-aa61-1d81be4009ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/1D U Net/models/16_epochs'\n",
        "torch.save(model, PATH)\n",
        "torch.max(softmax_mod(model(temp[0:64])[0]).transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type UNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type inconv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type double_conv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type down. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type up. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type outconv. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 1, 3, 4, 3, 1, 1,\n",
              "        3, 1, 3, 3, 2, 2, 4, 2, 4, 1, 2, 4, 1, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4,\n",
              "        4, 4, 2, 3, 4, 1, 3, 1, 1, 1, 3, 3, 1, 4, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1eqC1X_qcKK_",
        "colab": {}
      },
      "source": [
        "torch.max(y_f[0:64][0].transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVyp9sro8cXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def softmax_mod(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "def nll_indexing(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1].mean()\n",
        "\n",
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True)\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkA4l-qxl7pr",
        "colab_type": "code",
        "outputId": "49051bba-9207-4339-c860-f2af0bec1136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "### ADAM optimiser\n",
        "\n",
        "### training loop\n",
        "\n",
        "\n",
        "def softmax_mod(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "def nll_indexing(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1].mean()\n",
        "\n",
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True)\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))\n",
        "\n",
        "\n",
        "#soft = softmax_mod(out).transpose(1,2)\n",
        "#soft.shape\n",
        "lr = 4e-4\n",
        "epochs = 4\n",
        "#n = 7391\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "loss_func2 = torch.nn.L1Loss\n",
        "#def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
        "\n",
        "def accuracy_mod(out, yb): return (torch.argmax(out, dim=2)==yb-1).float().mean()\n",
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/EWT/models/EWT_LS1_155_epochs'))\n",
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/EWT/models/HIGH_LR_EWT_LS1_23_epochs'))\n",
        "for epoch in range(epochs):\n",
        "    for i in range(300): ### i = 1:100 for training\n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = temp[start_i:end_i]\n",
        "        #yb = y_f[start_i:end_i]\n",
        "        target = temp2[start_i:end_i]\n",
        "            \n",
        "        out = model(xb)\n",
        "        #loss = loss_func(model(xb), yb.long())\n",
        "        #loss = nll2((log_softmax(model(xb))),y_onehot.long())\n",
        "        loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "        #rint(loss)\n",
        "        #loss = cross_entropy(out.squeeze(),yb)\n",
        "        #loss = criterion(out.transpose(1, 2), torch.max(yb.transpose(1, 2), 1)[1])\n",
        "        \n",
        "        \n",
        "        accuracy = accuracy_mod(softmax_mod(out.transpose(1, 2)),target.long())\n",
        "\n",
        "        loss.backward()\n",
        "      #for param in model.parameters():\n",
        "        #print(param.grad.data.sum())\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    print('accuracy',accuracy)\n",
        "    print(' > Epoch {:2d} loss: {:.3f}'.format((epoch+1), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e484fd0aa00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#n = 7391\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mloss_func2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLaBLu2-bXmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.178 92.87\n",
        "0.141 94.8 -> 85 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkuz9CwzTdwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = model.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/EWT/models'\n",
        "torch.save(st, mdl_path+'/HIGH_LR_EWT_LS1_40_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D4lkZ3hcM3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = model.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/EWT/models'\n",
        "torch.save(st, mdl_path+'/EWT_LS1_155_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhRPqM0LXdc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/gdrive/My Drive/1D U Net/models/15_epochs_ADAM'\n",
        "model = torch.load(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EiPnn5RLjsD",
        "colab_type": "code",
        "outputId": "7fdf6f72-e213-43e9-c190-afd68c3a8a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Validation\n",
        "model.eval()\n",
        "cnt2 = 0\n",
        "total_acc = 0\n",
        "val_ids = list(range(80,110,1))\n",
        "for i in val_ids: ### i = 1:100 for training, 100-114 for validation\n",
        "    \n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i]\n",
        "    yb = y_f[start_i:end_i]\n",
        "    target = temp2[start_i:end_i]\n",
        "    \n",
        "    hidden=None\n",
        "    out = model(xb)\n",
        "    \n",
        "    loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "        \n",
        "    accuracy = accuracy_mod(softmax_mod(out.transpose(1, 2)),target.long())\n",
        "    total_acc = total_acc + accuracy\n",
        "    cnt2 = cnt2+1    \n",
        "    \n",
        "    print(' > Val {:2d} loss: {:.3f}'.format((i+1), loss.item()))\n",
        "    print('accuracy',accuracy)\n",
        "print(total_acc/cnt2)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Val 81 loss: 0.249\n",
            "accuracy tensor(0.9233)\n",
            " > Val 82 loss: 0.197\n",
            "accuracy tensor(0.9368)\n",
            " > Val 83 loss: 0.535\n",
            "accuracy tensor(0.8787)\n",
            " > Val 84 loss: 0.441\n",
            "accuracy tensor(0.9019)\n",
            " > Val 85 loss: 0.349\n",
            "accuracy tensor(0.9023)\n",
            " > Val 86 loss: 0.435\n",
            "accuracy tensor(0.8804)\n",
            " > Val 87 loss: 0.091\n",
            "accuracy tensor(0.9648)\n",
            " > Val 88 loss: 0.208\n",
            "accuracy tensor(0.9360)\n",
            " > Val 89 loss: 0.439\n",
            "accuracy tensor(0.8940)\n",
            " > Val 90 loss: 0.077\n",
            "accuracy tensor(0.9673)\n",
            " > Val 91 loss: 0.086\n",
            "accuracy tensor(0.9639)\n",
            " > Val 92 loss: 0.207\n",
            "accuracy tensor(0.9280)\n",
            " > Val 93 loss: 0.168\n",
            "accuracy tensor(0.9380)\n",
            " > Val 94 loss: 0.192\n",
            "accuracy tensor(0.9465)\n",
            " > Val 95 loss: 0.103\n",
            "accuracy tensor(0.9583)\n",
            " > Val 96 loss: 0.384\n",
            "accuracy tensor(0.8977)\n",
            " > Val 97 loss: 0.483\n",
            "accuracy tensor(0.8743)\n",
            " > Val 98 loss: 0.233\n",
            "accuracy tensor(0.9250)\n",
            " > Val 99 loss: 0.252\n",
            "accuracy tensor(0.9180)\n",
            " > Val 100 loss: 0.530\n",
            "accuracy tensor(0.8855)\n",
            " > Val 101 loss: 0.276\n",
            "accuracy tensor(0.9189)\n",
            " > Val 102 loss: 0.584\n",
            "accuracy tensor(0.8801)\n",
            " > Val 103 loss: 0.452\n",
            "accuracy tensor(0.8950)\n",
            " > Val 104 loss: 0.210\n",
            "accuracy tensor(0.9355)\n",
            " > Val 105 loss: 0.426\n",
            "accuracy tensor(0.8984)\n",
            " > Val 106 loss: 2.133\n",
            "accuracy tensor(0.6733)\n",
            " > Val 107 loss: 2.475\n",
            "accuracy tensor(0.6665)\n",
            " > Val 108 loss: 2.485\n",
            "accuracy tensor(0.6003)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-af67f31b1f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnll_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## Negative log likelihood of log softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e11dbf57ba7f>\u001b[0m in \u001b[0;36mnll_final\u001b[0;34m(soft, target)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mbatch_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m#out = batch_var.mean()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index -5 is out of bounds for dimension 0 with size 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4DlfHyNhV2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### complete sm_preds_fn\n",
        "sm_preds = []\n",
        "for i in range(118):\n",
        "    \n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp_ls[start_i:end_i]\n",
        "    yb = y_f[start_i:end_i]\n",
        "    target = temp2[start_i:end_i]\n",
        "        \n",
        "    out = model(xb)\n",
        "    sm_preds_val = softmax_mod(out.transpose(1, 2))\n",
        "    sm_preds_fn = torch.argmax(sm_preds_val, dim=2)+1\n",
        "    sm_preds.append(sm_preds_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNhjwb3ZhWpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = []\n",
        "pred = []\n",
        "for i in range(80,108):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp_ls[start_i:end_i]\n",
        "    yb = y_f[start_i:end_i]\n",
        "    target = temp2[start_i:end_i]\n",
        "    s1_true = np.where(target[0] == 3)\n",
        "    s1_pred = np.where(sm_preds[i][0] == 3)\n",
        "    tr.append(s1_true)\n",
        "    pred.append(s1_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIUsumQjhaZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(28):\n",
        "    print(i)\n",
        "    print(tr[i])\n",
        "    print(pred[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8n_gh9TLj8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzRgTqX-LmHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMiRFFF1EW_l",
        "colab_type": "code",
        "outputId": "b35d529f-892b-4642-9c41-de085b610bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "### 17 epocks ADAM\n",
        "torch.max(softmax_mod(model(temp[0:64].cuda())[0]).transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
              "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpadUtnWpXmI",
        "colab_type": "code",
        "outputId": "6e2030fd-d8f8-4ad0-8067-0e570c1e9069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "### 15 epocks ADAM\n",
        "torch.max(softmax_mod(model(temp[0:64])[0]).transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
              "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 4, 4, 4,\n",
              "        4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuwFNcpPoCUR",
        "colab_type": "code",
        "outputId": "924593b1-9d93-4f63-89e3-5f8b88017526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "## 10 epochs adam\n",
        "torch.max(softmax_mod(model(temp[0:64])[0]).transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 4, 4, 4, 4, 3, 1, 1, 2, 1, 3, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
              "        4, 2, 3, 3, 2, 3, 3, 2, 1, 3, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2,\n",
              "        1, 4, 4, 4, 4, 4, 4, 1, 3, 1, 1, 4, 4, 4, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzXaO-jXo9aN",
        "colab_type": "code",
        "outputId": "07b5c0d3-b296-44d0-b89a-897b5f0eed6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "torch.max(y_f[0:64][0].transpose(0,1),1)[1]+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
              "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n79bPjMJ85n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "bs = 64\n",
        "start_i = i*bs\n",
        "end_i = start_i+bs\n",
        "xb = temp[start_i:end_i]\n",
        "yb = y_f[start_i:end_i]\n",
        "target = temp2[start_i:end_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbPi03K8-4W",
        "colab_type": "code",
        "outputId": "3b1bc118-a6ba-4546-9438-9e00d1804ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "yb.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYW5OJ619TMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_XsWQlS9FrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = model(xb)\n",
        "k1 = softmax(out.transpose(1, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-whIkA09Wn3",
        "colab_type": "code",
        "outputId": "5a4e931d-e570-47ed-aad1-20092ded8a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "k1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSIhQs3l9ZFH",
        "colab_type": "code",
        "outputId": "38e8c9d5-dba7-470a-dc53-455ecfac54b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a1 = k1[1][10]\n",
        "a1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6KT3pz79gs1",
        "colab_type": "code",
        "outputId": "de280b47-3005-42f8-bfe9-95fb7ba1c716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2807, 0.2691, 0.2047, 0.2455], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67vdjcWeD2Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k23 = torch.argmax(k1, dim=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2m7qIJhD9GS",
        "colab_type": "code",
        "outputId": "2dfc710b-f5ed-448e-f440-4c505727e5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "k23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0,  ..., 1, 0, 1],\n",
              "        [3, 1, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 1, 0, 1],\n",
              "        ...,\n",
              "        [0, 1, 0,  ..., 1, 1, 1],\n",
              "        [2, 1, 0,  ..., 1, 0, 1],\n",
              "        [1, 0, 3,  ..., 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKgSGAbx_A4H",
        "colab_type": "code",
        "outputId": "646a8b48-ac0b-48a3-c9c0-05515f50df1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "k1[63][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2545, 0.2648, 0.2245, 0.2561], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpt4uCMaBhjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k1[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-MXrHyi-pII",
        "colab_type": "code",
        "outputId": "f38880c2-8aa3-48b9-d5e8-ccd0f0174e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "def nll23(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1]\n",
        "a12 = nll23(k1, target.long())\n",
        "a12"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2521, -0.2443, -0.2466,  ..., -0.2663, -0.2884, -0.2597],\n",
              "        [-0.2568, -0.2694, -0.2558,  ..., -0.2394, -0.2272, -0.2444],\n",
              "        [-0.2521, -0.2443, -0.2466,  ..., -0.2394, -0.2272, -0.2444],\n",
              "        ...,\n",
              "        [-0.2521, -0.2443, -0.2466,  ..., -0.2762, -0.2614, -0.2754],\n",
              "        [-0.2568, -0.2242, -0.2108,  ..., -0.2394, -0.2272, -0.2444],\n",
              "        [-0.2521, -0.2443, -0.2466,  ..., -0.2762, -0.2614, -0.2205]],\n",
              "       grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJLk2StbHpER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True)\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBUuEjp3IBPp",
        "colab_type": "code",
        "outputId": "266342bb-8982-45d3-ada8-33ab61a386ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a23 = nll_final(k1, target.long())\n",
        "a23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2497]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMp6t0UzIGIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevP6pdTGqXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knew = [k1[0][0][3], k1[0][1][3], k1[0][2][3]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ2-9oLoHTmC",
        "colab_type": "code",
        "outputId": "cf8abe3d-42c5-49fb-d39b-f480e7a2d4dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "knew"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.2521, grad_fn=<SelectBackward>),\n",
              " tensor(0.2269, grad_fn=<SelectBackward>),\n",
              " tensor(0.2368, grad_fn=<SelectBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6a_gp9XG3Le",
        "colab_type": "code",
        "outputId": "6314069b-eb20-4545-d810-359f9060b64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(k1[1][0][1], k1[1][1][1], k1[1][2][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2120, grad_fn=<SelectBackward>) tensor(0.2694, grad_fn=<SelectBackward>) tensor(0.2443, grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWpg1_MZIl2c",
        "colab_type": "code",
        "outputId": "53797f0d-9e9a-4b99-8394-555654a45c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "k1[2][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2582, 0.2570, 0.2418, 0.2431], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2NW5vHKHAOq",
        "colab_type": "code",
        "outputId": "0e4e3931-3542-4474-d5ce-159e446acad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(k1[63][0][1], k1[63][1][1], k1[63][2][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2648, grad_fn=<SelectBackward>) tensor(0.2571, grad_fn=<SelectBackward>) tensor(0.2335, grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNB7kWWSCIZf",
        "colab_type": "code",
        "outputId": "033ac9fa-7dc0-4a4a-ab28-c49fe5557ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a12.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyow5eHI-_NX",
        "colab_type": "code",
        "outputId": "0aaadf56-b636-443d-8a94-1469d935ce7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 4., 4.,  ..., 2., 2., 2.],\n",
              "        [2., 2., 2.,  ..., 4., 4., 4.],\n",
              "        [4., 4., 4.,  ..., 2., 3., 3.],\n",
              "        ...,\n",
              "        [4., 4., 4.,  ..., 2., 2., 2.],\n",
              "        [2., 2., 2.,  ..., 1., 1., 2.],\n",
              "        [2., 2., 2.,  ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ3e91I7KAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}