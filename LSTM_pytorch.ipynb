{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjayKumarGogineni777/Heart-Sound-Segmentation/blob/master/LSTM_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1E_a8NOToKw",
        "colab_type": "code",
        "outputId": "8d200f6e-89f6-4ce5-fed2-79cdc6137cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaSOGufvRIJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "mat_contents = sio.loadmat('/content/gdrive/My Drive/1D U Net/EWT/EWT_LS1_features.mat')\n",
        "labels = sio.loadmat('/content/gdrive/My Drive/1D U Net/states_normal.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxPgKb3yzJhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "### Stride 8\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 56339\n",
        "temp2 = torch.randn(elements,64)\n",
        "cnt2 = 0\n",
        "for i in range(792):\n",
        "  a = labels['concat_states'][0][i].shape\n",
        "  num = a[0]//8\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    if j*8+64< a[0]:\n",
        "      a2 = labels['concat_states'][0][i][j*8:(j*8+64)]\n",
        "    \n",
        "      a2 = torch.from_numpy(np.transpose(a2))\n",
        "      temp2[cnt2] = a2\n",
        "      cnt2 = cnt2+1\n",
        "      \n",
        "temp = torch.randn(elements, 4, 64)\n",
        "cnt2 = 0\n",
        "for i in range(792):\n",
        "  a = mat_contents['LS1_features'][0][i].shape\n",
        "  num = a[0]//8   \n",
        "  \n",
        "  for j in range(num):\n",
        "    if j*8+64< a[0]:\n",
        "      a2 = mat_contents['LS1_features'][0][i][j*8:(j*8+64)]\n",
        "    \n",
        "      a2 = torch.from_numpy(np.transpose(a2))\n",
        "      temp[cnt2] = a2\n",
        "      cnt2 = cnt2+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ycgRATpPzJwv",
        "colab": {}
      },
      "source": [
        "## Satets/ Labels\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "    \n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "temp2 = torch.randn(elements,64)\n",
        "cnt2 = 0\n",
        "for i in range(760):\n",
        "  a = labels['concat_states'][0][i].shape\n",
        "  num = a[0]//64\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    a2 = labels['concat_states'][0][i][j*64:(j*64+64)]\n",
        "    \n",
        "    a2 = torch.from_numpy(np.transpose(a2))\n",
        "    temp2[cnt2] = a2\n",
        "    cnt2 = cnt2+1  \n",
        "\n",
        "## Features\n",
        "import numpy as np\n",
        "import torch\n",
        "elements = 7104\n",
        "temp = torch.randn(elements,4,64)\n",
        "cnt = 0\n",
        "for i in range(760):\n",
        "  a = mat_contents['LS1_features'][0][i].shape\n",
        "  num = a[0]//64\n",
        "  #print(num)\n",
        "  for j in range(num):\n",
        "    a2 = mat_contents['LS1_features'][0][i][j*64:(j*64+64)]\n",
        "    a2 = torch.from_numpy(np.transpose(a2))\n",
        "    #a2 = torch.from_numpy(np.array(a2))\n",
        "    temp[cnt] = a2\n",
        "    cnt = cnt+1\n",
        "     \n",
        "            \n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n-0d46zbcEN",
        "colab_type": "code",
        "outputId": "a62f8d98-e1a3-4b65-de11-59c559930088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "# initializing the hidden state to 0\n",
        "hidden=None\n",
        "\n",
        "embeds_out = temp[0:64].transpose(1,2)\n",
        "lstm = nn.LSTM(input_size=4, hidden_size=512, num_layers=3, batch_first=True)\n",
        "lstm_out, h = lstm(embeds_out, hidden)\n",
        "fc = nn.Linear(in_features=512, out_features=4)\n",
        "fc_out = fc(lstm_out.contiguous().view(-1, 512))\n",
        "\n",
        "print ('LSTM layer output shape', lstm_out.shape)\n",
        "\n",
        "print ('FC layer output shape', fc_out.shape)\n",
        "#print ('LSTM layer output ', lstm_out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM layer output shape torch.Size([64, 64, 512])\n",
            "FC layer output shape torch.Size([4096, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOd46Azn2o-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(lstm, fc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LSjQPky22kn",
        "colab_type": "code",
        "outputId": "42e6ac19-9d3b-4d76-af6a-5b500c1ea34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f1bdf0589e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY56J-dLcbhv",
        "colab_type": "code",
        "outputId": "e533919f-8918-48d9-c7a6-16de926219aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "out = fc_out.reshape(64,64,4)\n",
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvfq8X8NWUR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class mod1(nn.Module):\n",
        "    '''(conv => BN => ReLU ) * 1'''\n",
        "    def __init__(self):\n",
        "        super(mod1, self).__init__()\n",
        "        \n",
        "        #self.lstm = nn.LSTM(input_size=4, hidden_size=256, num_layers=2, batch_first=True).cuda()\n",
        "        self.lstm = nn.GRU(input_size=4, hidden_size=256, num_layers=2, batch_first=True).cuda()\n",
        "        self.fc = nn.Linear(in_features=256, out_features=4).cuda()\n",
        "    def forward(self, x, hidden):\n",
        "        lstm_out, h = self.lstm(x, hidden)\n",
        "        fc_out = self.fc(lstm_out.contiguous().view(-1, 256))\n",
        "        out = fc_out.reshape(64,64,4)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "model = mod1()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGNwzFc0ayaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#st = model.state_dict()\n",
        "#mdl_path = '/content/gdrive/My Drive/1D U Net/models'\n",
        "model = torch.load('/content/gdrive/My Drive/1D U Net/models/complete_adam_5_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A9gxjm6bTqZ",
        "colab_type": "code",
        "outputId": "c9f7002f-40ce-4c89-968f-b230bedf6e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mod1().parameters()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f68d07bff68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGJTfFOychT-",
        "colab_type": "code",
        "outputId": "279339e8-3936-447c-80ca-e45592773012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "### ADAM optimiser\n",
        "\n",
        "### training loop\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "def softmax_mod(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "def nll_indexing(soft,target):\n",
        "  ## soft : 64,64,4\n",
        "  ## target : 64,64,4 or 64, 64\n",
        "  \n",
        "  return -soft[range(target.shape[0]),range(target.shape[1]), target-1].mean()\n",
        "\n",
        "def nll_final(soft,target):\n",
        "  batch_var = torch.zeros([64, 64] , requires_grad=True)\n",
        "  out = torch.zeros([1, 1] , requires_grad=True).cuda()\n",
        "  for i in range(64):\n",
        "    for j in range(64):\n",
        "      ind = target[i][j]-1\n",
        "      batch_var[i][j] = soft[i][j][ind]\n",
        "      out = out + soft[i][j][ind]\n",
        "  #out = batch_var.mean()\n",
        "  return -1*(out/(64*64))\n",
        "\n",
        "\n",
        "#soft = softmax_mod(out).transpose(1,2)\n",
        "#soft.shape\n",
        "\n",
        "lr = 5e-4\n",
        "epochs = 6\n",
        "n = 7391\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "loss_func2 = torch.nn.L1Loss\n",
        "#def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
        "\n",
        "def accuracy_mod(out, yb): return (torch.argmax(out, dim=2)==yb-1).float().mean()\n",
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()\n",
        "\n",
        "#model = LSTM()\n",
        "#opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "import torch\n",
        "from torch import nn\n",
        "# initializing the hidden state to 0\n",
        "hidden=None\n",
        "\n",
        "\n",
        "\n",
        "#lstm = nn.LSTM(input_size=4, hidden_size=512, num_layers=3, batch_first=True).cuda()\n",
        "#fc = nn.Linear(in_features=512, out_features=4).cuda()\n",
        "#opt = torch.optim.Adam(list(lstm.parameters()) +\n",
        "                             #list(fc.parameters()), lr=0.0001)##initially 1e-3\n",
        "#lstm = torch.load('/content/gdrive/My Drive/1D U Net/models/lstm_adam_5_epochs')\n",
        "#fc = torch.load('/content/gdrive/My Drive/1D U Net/models/fc_adam_5_epochs')\n",
        "\n",
        "\n",
        "#model = mod1()\n",
        "\n",
        "\n",
        "\n",
        "#opt = torch.optim.Adam(model.parameters(), lr = lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2, amsgrad=False)\n",
        "#opt = torch.optim.RMSprop(model.parameters(), lr = lr, alpha=0.99, eps=1e-08, weight_decay=1e-2, momentum=0, centered=False)\n",
        "\n",
        "#opt = torch.optim.LBFGS(model.parameters(), lr = lr)\n",
        "opt = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "#model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/models/small_complete_adam_230_epochs'))\n",
        "\n",
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/1D U Net/models/LS_EWT_GRU_34_epochs_stride_8'))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(200): ### i = 1:100 for training\n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = temp[start_i:end_i].cuda()\n",
        "        \n",
        "        target = temp2[start_i:end_i].cuda()\n",
        "        \n",
        "        embeds_out = xb.transpose(1,2)\n",
        "        #lstm_out, h = lstm(embeds_out, hidden)\n",
        "        #fc_out = fc(lstm_out.contiguous().view(-1, 512))\n",
        "        #out = fc_out.reshape(64,64,4)\n",
        "        \n",
        "        out = model(embeds_out, hidden)\n",
        "        \n",
        "        #loss = nll_final((softmax_mod(out.transpose(1, 2))),target.long()) ## Negative log likelihood of log softmax\n",
        "        loss = nll_final((softmax_mod(out)),target.long()) ## Negative log likelihood of log softmax\n",
        "        \n",
        "        accuracy = accuracy_mod(softmax_mod(out),target.long())\n",
        "\n",
        "        loss.backward()\n",
        "     \n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    print('accuracy',accuracy)\n",
        "    print(' > Epoch {:2d} loss: {:.3f}'.format((epoch+1), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy tensor(0.6970, device='cuda:0')\n",
            " > Epoch  1 loss: 0.735\n",
            "accuracy tensor(0.6785, device='cuda:0')\n",
            " > Epoch  2 loss: 0.775\n",
            "accuracy tensor(0.6956, device='cuda:0')\n",
            " > Epoch  3 loss: 0.738\n",
            "accuracy tensor(0.7112, device='cuda:0')\n",
            " > Epoch  4 loss: 0.719\n",
            "accuracy tensor(0.7197, device='cuda:0')\n",
            " > Epoch  5 loss: 0.712\n",
            "accuracy tensor(0.7310, device='cuda:0')\n",
            " > Epoch  6 loss: 0.653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd5M0v0yYLju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = model.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/models'\n",
        "#torch.save(st, mdl_path+'/50_items_adam_24_epochs')\n",
        "torch.save(st, mdl_path+'/LS_EWT_GRU_40_epochs_stride_8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0toG--qjHUVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "0.3178\n",
        "0.299\n",
        "0.283\n",
        "0.278, 88.62 -174\n",
        "\n",
        "0.275 88.40\n",
        "0.273 88.53\n",
        "0.279 88.26\n",
        "0.270 88.75\n",
        "0.272 88.67"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJ01NOMYMun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ksc7yeMYMxO",
        "colab_type": "code",
        "outputId": "48a876fe-e243-48d0-a5db-550f01bbbf69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Validation\n",
        "#model.eval()\n",
        "val_ids = list(range(80,109,1))\n",
        "for i in val_ids: ### i = 1:100 for training, 100-114 for validation\n",
        "    \n",
        "    #for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i].cuda()\n",
        "    #yb = y_f[start_i:end_i].cuda()\n",
        "    target = temp2[start_i:end_i].cuda()\n",
        "    embeds_out = xb.transpose(1,2)\n",
        "    hidden=None\n",
        "    out = model(embeds_out, hidden)\n",
        "    \n",
        "    loss = nll_final((softmax_mod(out)),target.long()) ## Negative log likelihood of log softmax\n",
        "        \n",
        "    accuracy = accuracy_mod(softmax_mod(out),target.long())\n",
        "\n",
        "        \n",
        "    \n",
        "    print(' > Val {:2d} loss: {:.3f}'.format((i+1), loss.item()))\n",
        "    print('accuracy',accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Val 81 loss: 0.480\n",
            "accuracy tensor(0.8220, device='cuda:0')\n",
            " > Val 82 loss: 0.381\n",
            "accuracy tensor(0.8552, device='cuda:0')\n",
            " > Val 83 loss: 0.511\n",
            "accuracy tensor(0.7979, device='cuda:0')\n",
            " > Val 84 loss: 0.549\n",
            "accuracy tensor(0.7842, device='cuda:0')\n",
            " > Val 85 loss: 0.392\n",
            "accuracy tensor(0.8408, device='cuda:0')\n",
            " > Val 86 loss: 0.506\n",
            "accuracy tensor(0.8020, device='cuda:0')\n",
            " > Val 87 loss: 0.634\n",
            "accuracy tensor(0.7551, device='cuda:0')\n",
            " > Val 88 loss: 0.498\n",
            "accuracy tensor(0.7991, device='cuda:0')\n",
            " > Val 89 loss: 0.604\n",
            "accuracy tensor(0.7583, device='cuda:0')\n",
            " > Val 90 loss: 0.421\n",
            "accuracy tensor(0.8320, device='cuda:0')\n",
            " > Val 91 loss: 0.455\n",
            "accuracy tensor(0.8142, device='cuda:0')\n",
            " > Val 92 loss: 0.502\n",
            "accuracy tensor(0.7937, device='cuda:0')\n",
            " > Val 93 loss: 0.860\n",
            "accuracy tensor(0.6465, device='cuda:0')\n",
            " > Val 94 loss: 1.077\n",
            "accuracy tensor(0.5452, device='cuda:0')\n",
            " > Val 95 loss: 0.417\n",
            "accuracy tensor(0.8384, device='cuda:0')\n",
            " > Val 96 loss: 0.436\n",
            "accuracy tensor(0.8359, device='cuda:0')\n",
            " > Val 97 loss: 0.482\n",
            "accuracy tensor(0.8237, device='cuda:0')\n",
            " > Val 98 loss: 0.351\n",
            "accuracy tensor(0.8579, device='cuda:0')\n",
            " > Val 99 loss: 0.517\n",
            "accuracy tensor(0.8003, device='cuda:0')\n",
            " > Val 100 loss: 0.550\n",
            "accuracy tensor(0.7900, device='cuda:0')\n",
            " > Val 101 loss: 0.352\n",
            "accuracy tensor(0.8728, device='cuda:0')\n",
            " > Val 102 loss: 0.529\n",
            "accuracy tensor(0.7939, device='cuda:0')\n",
            " > Val 103 loss: 0.332\n",
            "accuracy tensor(0.8857, device='cuda:0')\n",
            " > Val 104 loss: 0.639\n",
            "accuracy tensor(0.7415, device='cuda:0')\n",
            " > Val 105 loss: 0.819\n",
            "accuracy tensor(0.6692, device='cuda:0')\n",
            " > Val 106 loss: 0.723\n",
            "accuracy tensor(0.7058, device='cuda:0')\n",
            " > Val 107 loss: 0.591\n",
            "accuracy tensor(0.7634, device='cuda:0')\n",
            " > Val 108 loss: 0.616\n",
            "accuracy tensor(0.7502, device='cuda:0')\n",
            " > Val 109 loss: 0.564\n",
            "accuracy tensor(0.7634, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o04dr6Gp6ajQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "63"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBAvKx4SOwW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_preds = []\n",
        "bs = 64\n",
        "for i in range(109):\n",
        "    \n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i].cuda()\n",
        "    yb = y_f[start_i:end_i].cuda()\n",
        "    target = temp2[start_i:end_i].cuda()\n",
        "    embeds_out = xb.transpose(1,2)\n",
        "    #lstm = nn.LSTM(input_size=4, hidden_size=512, num_layers=3, batch_first=True)\n",
        "    #lstm_out, h = lstm(embeds_out, hidden)\n",
        "    #fc = nn.Linear(in_features=512, out_features=4)\n",
        "    #fc_out = fc(lstm_out.contiguous().view(-1, 512))\n",
        "    out = model(embeds_out, hidden)  \n",
        "    #out = model(xb)\n",
        "    sm_preds_val = softmax_mod(out)\n",
        "    sm_preds_fn = torch.argmax(sm_preds_val, dim=2)+1\n",
        "    sm_preds.append(sm_preds_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-fiWSQiQWsg",
        "colab_type": "code",
        "outputId": "c858d310-44ed-4914-c9b8-0d41b220d48e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhw97ne-O-mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = []\n",
        "pred = []\n",
        "for i in range(80,108):\n",
        "    start_i = i*bs\n",
        "    end_i = start_i+bs\n",
        "    xb = temp[start_i:end_i]\n",
        "    yb = y_f[start_i:end_i]\n",
        "    target = temp2[start_i:end_i]\n",
        "    s1_true = np.where(temp2[start_i:end_i][0] == 1)\n",
        "    temp234 = sm_preds[i].cpu()\n",
        "    s1_pred = np.where(temp234[0] == 1)\n",
        "    tr.append(s1_true)\n",
        "    pred.append(s1_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N51dPMsP1eh",
        "colab_type": "code",
        "outputId": "007d0cff-86e9-4cd6-aa23-32aec3722f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s1_true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([18, 19, 20, 21, 22, 53, 54, 55, 56, 57]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9XH3CejQqx6",
        "colab_type": "code",
        "outputId": "9de0f707-2d90-453d-c977-c972d3c63921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "i = 105\n",
        "start_i = i*bs\n",
        "end_i = start_i+bs\n",
        "np.where(temp2[start_i:end_i][0]==3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([44, 45, 46, 47, 48]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIMQ3zlGPbsL",
        "colab_type": "code",
        "outputId": "beb5e39e-df23-49dc-b60b-6c8c416ee8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "sm_preds[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 4, 4,  ..., 2, 2, 2],\n",
              "        [4, 4, 1,  ..., 4, 4, 4],\n",
              "        [4, 4, 4,  ..., 2, 2, 2],\n",
              "        ...,\n",
              "        [4, 4, 4,  ..., 4, 1, 1],\n",
              "        [3, 1, 1,  ..., 2, 2, 2],\n",
              "        [4, 4, 3,  ..., 4, 4, 4]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDnCPQJyPYfD",
        "colab_type": "code",
        "outputId": "4098d6cc-cb57-43d2-d82b-f23ffea920dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s1_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_KhZPXvPBXM",
        "colab_type": "code",
        "outputId": "769f91d5-55c5-4c25-e0fa-79407cf2bf85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(29):\n",
        "    print(i)\n",
        "    print(tr[i])\n",
        "    print(pred[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(array([23, 24, 25, 26, 27, 28, 29]),)\n",
            "(array([20, 21, 22, 23, 24, 25, 26, 27]),)\n",
            "1\n",
            "(array([19, 20, 21, 22, 23, 24, 25, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([ 0,  1,  2,  3, 21, 22, 23, 24, 25, 26, 57, 58, 59, 60, 61, 62, 63]),)\n",
            "2\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6, 37, 38, 39, 40, 41, 42, 43]),)\n",
            "(array([37, 38, 39, 40, 41, 42, 43, 44]),)\n",
            "3\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12]),)\n",
            "(array([ 7,  8,  9, 10, 11, 12, 13]),)\n",
            "4\n",
            "(array([ 0,  1, 54, 55, 56, 57, 58, 59, 60]),)\n",
            "(array([ 0, 55, 56, 57, 58, 59, 60]),)\n",
            "5\n",
            "(array([36, 37, 38, 39, 40, 41, 42]),)\n",
            "(array([ 2, 34, 35, 36, 37, 38, 39, 40, 41]),)\n",
            "6\n",
            "(array([13, 14, 15, 16, 17, 18, 19, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([16, 17, 18, 19, 20, 21, 60, 61, 62, 63]),)\n",
            "7\n",
            "(array([18, 19, 20, 21, 22, 23, 24, 58, 59, 60, 61, 62, 63]),)\n",
            "(array([18, 19, 20, 21, 22, 23, 24, 59, 60, 61, 62, 63]),)\n",
            "8\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 44, 45, 46, 47, 48, 49, 50]),)\n",
            "(array([ 7,  8,  9, 10, 11, 12, 13, 45, 46, 47, 48, 49, 50, 51]),)\n",
            "9\n",
            "(array([ 0, 31, 32, 33, 34, 35, 36, 37]),)\n",
            "(array([33, 34, 35, 36, 37, 38]),)\n",
            "10\n",
            "(array([29, 30, 31, 32, 33, 34, 35]),)\n",
            "(array([ 0, 28, 29, 30, 31, 32, 33, 34]),)\n",
            "11\n",
            "(array([20, 21, 22, 23, 24, 25, 26, 55, 56, 57, 58, 59, 60, 61]),)\n",
            "(array([ 0,  1, 20, 21, 22, 23, 24, 25, 26, 55, 56, 57, 58, 59, 60, 61]),)\n",
            "12\n",
            "(array([ 0,  1,  2, 29, 30, 31, 32, 33, 34, 35, 61, 62, 63]),)\n",
            "(array([ 0, 28, 29, 30, 31, 32, 33, 34, 61, 62, 63]),)\n",
            "13\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 48, 49, 50, 51, 52, 53, 54]),)\n",
            "(array([ 0,  1,  2,  3,  4, 49, 50, 51, 52, 53, 54]),)\n",
            "14\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6, 62, 63]),)\n",
            "(array([ 1,  2, 63]),)\n",
            "15\n",
            "(array([40, 41, 42, 43, 44, 45, 46]),)\n",
            "(array([ 9, 10, 11, 13, 41, 42, 43, 44, 45, 46, 47]),)\n",
            "16\n",
            "(array([ 4,  5,  6,  7,  8,  9, 10, 36, 37, 38, 39, 40, 41, 42]),)\n",
            "(array([ 4,  5,  6,  7,  8,  9, 35, 36, 37, 38, 39, 40, 41, 42]),)\n",
            "17\n",
            "(array([ 1,  2,  3,  4,  5,  6,  7, 38, 39, 40, 41, 42, 43, 44]),)\n",
            "(array([ 3,  4,  5,  6,  7, 38, 39, 40, 41, 42, 43, 44]),)\n",
            "18\n",
            "(array([ 9, 10, 11, 12, 13, 14, 15]),)\n",
            "(array([ 3,  6,  7,  9, 10, 11, 12, 13, 14, 15, 16]),)\n",
            "19\n",
            "(array([12, 13, 14, 15, 16, 17, 18, 52, 53, 54, 55, 56, 57, 58]),)\n",
            "(array([13, 14, 15, 16, 17, 18, 19, 53, 54, 55, 56, 57, 58]),)\n",
            "20\n",
            "(array([ 0,  1, 28, 29, 30, 31, 32, 33, 34, 61, 62, 63]),)\n",
            "(array([ 0, 29, 30, 31, 32, 33, 34, 35, 63]),)\n",
            "21\n",
            "(array([22, 23, 24, 25, 26, 27, 28]),)\n",
            "(array([10, 11, 12, 13, 14, 15, 16, 24, 25, 26, 27, 28]),)\n",
            "22\n",
            "(array([ 8,  9, 10, 11, 12, 13, 14, 50, 51, 52, 53, 54, 55, 56]),)\n",
            "(array([ 9, 10, 11, 12, 13, 14, 15, 49, 50, 51, 52, 53, 54, 55, 56]),)\n",
            "23\n",
            "(array([ 5,  6,  7,  8,  9, 10, 11, 43, 44, 45, 46, 47, 48, 49]),)\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 45, 46, 47, 48, 49, 50]),)\n",
            "24\n",
            "(array([ 0,  1,  2,  3,  4,  5,  6, 39, 40, 41, 42, 43, 44, 45]),)\n",
            "(array([ 1,  2,  3,  4,  5,  6,  7, 39, 40, 41, 42, 43, 44, 45, 46]),)\n",
            "25\n",
            "(array([29, 30, 31, 32, 33, 34, 35]),)\n",
            "(array([24, 25, 26, 27, 28, 29, 30, 31]),)\n",
            "26\n",
            "(array([35, 36, 37, 38, 39, 40, 41]),)\n",
            "(array([36, 37, 38, 39, 40, 41]),)\n",
            "27\n",
            "(array([ 6,  7,  8,  9, 10, 11, 12, 45, 46, 47, 48, 49, 50, 51]),)\n",
            "(array([ 7,  8,  9, 10, 11, 12, 13, 47, 48, 49]),)\n",
            "28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1e59e90eb637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vkDw3x73-co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = lstm.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/models'\n",
        "torch.save(st, mdl_path+'/lstm_adam_5_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m73Q87TO4K_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = fc.state_dict()\n",
        "mdl_path = '/content/gdrive/My Drive/1D U Net/models'\n",
        "torch.save(st, mdl_path+'/fc_adam_5_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9icnjDLqU1Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = torch.load('/content/gdrive/My Drive/1D U Net/models/lstm_adam_5_epochs')\n",
        "fc = torch.load('/content/gdrive/My Drive/1D U Net/models/fc_adam_5_epochs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ8EMYPEU1Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnFq2sd2e8dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_i = 0\n",
        "end_i = 1\n",
        "bs = 64\n",
        "xb = temp[start_i:end_i]\n",
        "xb.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}